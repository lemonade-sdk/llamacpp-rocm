name: Test Llama.cpp + ROCm
on:
  workflow_dispatch:
    inputs:
      operating_systems:
        description: 'Operating systems to test on (comma-separated: windows,ubuntu)'
        required: false
        default: 'windows,ubuntu'
      gfx_target:
        description: 'AMD GPU targets (comma-separated)'
        required: false
        default: 'gfx1151'
      release_tag:
        description: 'Release tag to test (e.g., b1001) or "latest" for the most recent release'
        required: false
        default: 'latest'

env:
  OPERATING_SYSTEMS: ${{ github.event.inputs.operating_systems || 'windows,ubuntu' }}
  GFX_TARGETS: ${{ github.event.inputs.gfx_target || 'gfx1151' }}
  RELEASE_TAG: ${{ github.event.inputs.release_tag || 'latest' }}

jobs:
  prepare-matrix:
    runs-on: ubuntu-22.04
    outputs:
      windows_matrix: ${{ steps.set-matrix.outputs.windows_matrix }}
      ubuntu_matrix: ${{ steps.set-matrix.outputs.ubuntu_matrix }}
      should_test_windows: ${{ steps.set-matrix.outputs.should_test_windows }}
      should_test_ubuntu: ${{ steps.set-matrix.outputs.should_test_ubuntu }}
      latest_release_tag: ${{ steps.get-release.outputs.latest_release_tag }}
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Get release tag
      id: get-release
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        release_input="${{ env.RELEASE_TAG }}"
        
        if [ "$release_input" = "latest" ]; then
          # Get the latest release tag
          release_tag=$(gh release list --limit 1 --json tagName --jq '.[0].tagName')
          echo "Using latest release: $release_tag"
        else
          # Use the specified release tag
          release_tag="$release_input"
          echo "Using specified release: $release_tag"
          
          # Verify the release exists
          if ! gh release view "$release_tag" >/dev/null 2>&1; then
            echo "Error: Release '$release_tag' does not exist"
            exit 1
          fi
        fi
        
        echo "latest_release_tag=$release_tag" >> $GITHUB_OUTPUT
        echo "Final release tag: $release_tag"
        
    - name: Set matrix
      id: set-matrix
      run: |
        targets="${{ env.GFX_TARGETS }}"
        operating_systems="${{ env.OPERATING_SYSTEMS }}"
        
        echo "Input targets: $targets"
        echo "Input operating systems: $operating_systems"

        # Convert targets to JSON array
        matrix_targets=$(echo "$targets" \
          | tr ',' '\n' \
          | sed 's/^ *//;s/ *$//' \
          | sed 's/^"//;s/"$//' \
          | jq -R . \
          | jq -s '{gfx_target: .}' \
          | jq -c)

        # Check which operating systems to test
        should_test_windows="false"
        should_test_ubuntu="false"
        
        if [[ "$operating_systems" == *"windows"* ]]; then
          should_test_windows="true"
          echo "windows_matrix=$matrix_targets" >> $GITHUB_OUTPUT
        fi
        
        if [[ "$operating_systems" == *"ubuntu"* ]]; then
          should_test_ubuntu="true"
          echo "ubuntu_matrix=$matrix_targets" >> $GITHUB_OUTPUT
        fi
        
        echo "should_test_windows=$should_test_windows" >> $GITHUB_OUTPUT
        echo "should_test_ubuntu=$should_test_ubuntu" >> $GITHUB_OUTPUT
        
        echo "Windows test: $should_test_windows"
        echo "Ubuntu test: $should_test_ubuntu"
        echo "Generated matrix: $matrix_targets"

  test-windows:
    runs-on: [stx-halo, Windows]
    needs: prepare-matrix
    if: needs.prepare-matrix.outputs.should_test_windows == 'true'
    strategy:
      matrix: ${{fromJson(needs.prepare-matrix.outputs.windows_matrix)}}
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download release artifacts
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        $releaseTag = "${{ needs.prepare-matrix.outputs.latest_release_tag }}"
        $target = "${{ matrix.gfx_target }}"
        $assetName = "llama-${releaseTag}-windows-rocm-${target}-x64.zip"
        
        Write-Host "Downloading release asset: $assetName"
        Write-Host "From release: $releaseTag"
        
        # Download the specific asset
        gh release download $releaseTag --pattern $assetName
        
        # Extract the downloaded zip file
        Write-Host "Extracting $assetName..."
        Expand-Archive -Path $assetName -DestinationPath "llama-binaries" -Force
        
        # List contents
        Write-Host "Contents of llama-binaries:"
        Get-ChildItem -Recurse "llama-binaries" | Format-Table Name, Length
        
    - name: Download test model
      run: |
        $modelUrl = "https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_0.gguf?download=true"
        $modelPath = "Qwen3-0.6B-Q4_0.gguf"
        
        Write-Host "Downloading test model from: $modelUrl"
        Invoke-WebRequest -Uri $modelUrl -OutFile $modelPath
        
        # Verify download
        if (Test-Path $modelPath) {
          $fileSize = (Get-Item $modelPath).Length
          Write-Host "Model downloaded successfully. Size: $fileSize bytes"
        } else {
          Write-Error "Failed to download model"
          exit 1
        }
        
    - name: Run llama-cli test
      run: |
        $llamaCliPath = "llama-binaries\llama-cli.exe"
        $modelPath = "Qwen3-0.6B-Q4_0.gguf"
        
        # Verify llama-cli exists
        if (-not (Test-Path $llamaCliPath)) {
          Write-Error "llama-cli.exe not found at: $llamaCliPath"
          Write-Host "Available files in llama-binaries:"
          Get-ChildItem -Recurse "llama-binaries"
          exit 1
        }
        
        Write-Host "Running llama-cli test..."
        Write-Host "Command: $llamaCliPath -m `"$modelPath`" -ngl 99 -p `"I believe the meaning of life is`" -st"
        
        # Run the command and capture output
        $output = & $llamaCliPath -m $modelPath -ngl 99 -p "I believe the meaning of life is" -st 2>&1 | Out-String
        
        Write-Host "=== LLAMA-CLI OUTPUT ==="
        Write-Host $output
        Write-Host "=== END OUTPUT ==="
        
        # Check for expected outputs
        $foundGpuOffload = $output -match "offloaded 29/29 layers to GPU"
        $foundThinkTag = $output -match "</think>"
        
        Write-Host "=== TEST RESULTS ==="
        Write-Host "Expected 'offloaded 29/29 layers to GPU': $(if ($foundGpuOffload) { 'FOUND' } else { 'NOT FOUND' })"
        Write-Host "Expected '</think>' tag: $(if ($foundThinkTag) { 'FOUND' } else { 'NOT FOUND' })"
        
        if ($foundGpuOffload -and $foundThinkTag) {
          Write-Host "✅ Test PASSED - Both expected outputs found"
        } else {
          Write-Host "❌ Test FAILED - Missing expected outputs"
          exit 1
        }

  test-ubuntu:
    runs-on: [stx-halo, Linux]
    needs: prepare-matrix
    if: needs.prepare-matrix.outputs.should_test_ubuntu == 'true'
    strategy:
      matrix: ${{fromJson(needs.prepare-matrix.outputs.ubuntu_matrix)}}
      fail-fast: false

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Download release artifacts
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        release_tag="${{ needs.prepare-matrix.outputs.latest_release_tag }}"
        target="${{ matrix.gfx_target }}"
        asset_name="llama-${release_tag}-ubuntu-rocm-${target}-x64.zip"
        
        echo "Downloading release asset: $asset_name"
        echo "From release: $release_tag"
        
        # Download the specific asset
        gh release download "$release_tag" --pattern "$asset_name"
        
        # Extract the downloaded zip file
        echo "Extracting $asset_name..."
        unzip -q "$asset_name" -d llama-binaries
        
        # List contents
        echo "Contents of llama-binaries:"
        find llama-binaries -type f -exec ls -la {} \;
        
    - name: Download test model
      run: |
        model_url="https://huggingface.co/unsloth/Qwen3-0.6B-GGUF/resolve/main/Qwen3-0.6B-Q4_0.gguf?download=true"
        model_path="Qwen3-0.6B-Q4_0.gguf"
        
        echo "Downloading test model from: $model_url"
        wget -O "$model_path" "$model_url"
        
        # Verify download
        if [ -f "$model_path" ]; then
          file_size=$(stat -c%s "$model_path")
          echo "Model downloaded successfully. Size: $file_size bytes"
        else
          echo "Failed to download model"
          exit 1
        fi
        
    - name: Set up library path
      run: |
        # Add the llama-binaries directory to LD_LIBRARY_PATH
        echo "LD_LIBRARY_PATH=$(pwd)/llama-binaries:$LD_LIBRARY_PATH" >> $GITHUB_ENV
        
    - name: Run llama-cli test
      run: |
        llama_cli_path="./llama-binaries/llama-cli"
        model_path="Qwen3-0.6B-Q4_0.gguf"
        
        # Make llama-cli executable
        chmod +x "$llama_cli_path"
        
        # Verify llama-cli exists
        if [ ! -f "$llama_cli_path" ]; then
          echo "llama-cli not found at: $llama_cli_path"
          echo "Available files in llama-binaries:"
          find llama-binaries -type f
          exit 1
        fi
        
        echo "Running llama-cli test..."
        echo "Command: $llama_cli_path -m \"$model_path\" -ngl 99 -p \"I believe the meaning of life is\" -st"
        
        # Run the command and capture output
        output=$("$llama_cli_path" -m "$model_path" -ngl 99 -p "I believe the meaning of life is" -st 2>&1)
        
        echo "=== LLAMA-CLI OUTPUT ==="
        echo "$output"
        echo "=== END OUTPUT ==="
        
        # Check for expected outputs
        if echo "$output" | grep -q "offloaded 29/29 layers to GPU"; then
          found_gpu_offload=true
        else
          found_gpu_offload=false
        fi
        
        if echo "$output" | grep -q "</think>"; then
          found_think_tag=true
        else
          found_think_tag=false
        fi
        
        echo "=== TEST RESULTS ==="
        echo "Expected 'offloaded 29/29 layers to GPU': $(if [ "$found_gpu_offload" = true ]; then echo 'FOUND'; else echo 'NOT FOUND'; fi)"
        echo "Expected '</think>' tag: $(if [ "$found_think_tag" = true ]; then echo 'FOUND'; else echo 'NOT FOUND'; fi)"
        
        if [ "$found_gpu_offload" = true ] && [ "$found_think_tag" = true ]; then
          echo "✅ Test PASSED - Both expected outputs found"
        else
          echo "❌ Test FAILED - Missing expected outputs"
          exit 1
        fi
